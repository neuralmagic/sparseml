{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e081b7",
   "metadata": {},
   "source": [
    "# Sparsifying MobileNetv2 from Scratch (Beans)\n",
    "\n",
    "In this example, we will demonstrate how to sparsify an image classification model from scratch using SparseML's PyTorch integration. We train and prune [MobileNetv2](https://pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v2.html) on the downstream [Beans dataset](https://huggingface.co/datasets/beans) using the Global Magnitude Pruning algorithm. \n",
    "\n",
    "## Agenda\n",
    "\n",
    "There are a few steps:\n",
    "\n",
    " 1. Setup the dataset\n",
    " 2. Setup the PyTorch training loop\n",
    " 3. Train a dense version of MobileNetv2\n",
    " 4. Run the GMP pruning algorithm on the dense model\n",
    " \n",
    "## Installation\n",
    "\n",
    "Install SparseML with `pip`:\n",
    "\n",
    "```\n",
    "pip install sparseml[torchvision]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad80edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sparseml\n",
    "import torchvision\n",
    "from sparseml.pytorch.optim import ScheduledModifierManager\n",
    "from sparseml.pytorch.utils import TensorBoardLogger, ModuleExporter, get_prunable_layers, tensor_sparsity\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79303b28",
   "metadata": {},
   "source": [
    "## Step 1: Setup Dataset\n",
    "\n",
    "Beans leaf dataset is a set of images of diseased and healthy leaves. Based on a leaf image, the goal of this task is to predict the disease type (Angular Leaf Spot and Bean Rust), if any.\n",
    "\n",
    "We will use the Hugging Face `datasets` library to download the data and the torchvision `ImageFolder` in the training loop.\n",
    "\n",
    "[Checkout the dataset card](https://huggingface.co/datasets/beans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans_dataset = datasets.load_dataset(\"beans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06fc4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/huggingface/datasets/downloads/extracted/eeb026374cf5ecfd5f40131a3159be9b9055ac21a3da11690e7eb4d117c99eee/train/bean_rust/bean_rust_train.84.jpg\n",
      "/home/ubuntu/.cache/huggingface/datasets/downloads/extracted/f287261265d2f9a3e8f87a5526a54d1847b17f7c3ec5714e5719432f2b3e4a73/validation/bean_rust/bean_rust_val.36.jpg\n"
     ]
    }
   ],
   "source": [
    "print(beans_dataset[\"train\"][0][\"image_file_path\"])\n",
    "print(beans_dataset[\"validation\"][0][\"image_file_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ecdebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/ubuntu/.cache/huggingface/datasets/downloads/extracted/eeb026374cf5ecfd5f40131a3159be9b9055ac21a3da11690e7eb4d117c99eee/train\"\n",
    "val_path = \"/home/ubuntu/.cache/huggingface/datasets/downloads/extracted/f287261265d2f9a3e8f87a5526a54d1847b17f7c3ec5714e5719432f2b3e4a73/validation\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d180bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# imagenet transforms\n",
    "imagenet_transform = transforms.Compose([\n",
    "   transforms.Resize(size=256, interpolation=transforms.InterpolationMode.BILINEAR, max_size=None, antialias=None),\n",
    "   transforms.CenterCrop(size=(224, 224)),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# datasets\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=train_path,\n",
    "    transform=imagenet_transform\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=val_path,\n",
    "    transform=imagenet_transform\n",
    ")\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=16)\n",
    "val_loader = DataLoader(val_dataset, BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132fc514",
   "metadata": {},
   "source": [
    "## Step 2: Setup PyTorch Training Loop\n",
    "\n",
    "We will use this training loop below. This is standard PyTorch functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c968c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "def run_model_one_epoch(model, data_loader, criterion, device, train=False, optimizer=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # loop through batches\n",
    "    for step, (inputs, labels) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # compute loss, run backpropogation\n",
    "        outputs = model(inputs)  # model returns logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # run evaluation\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        total_correct += torch.sum(predictions == labels).item()\n",
    "        total_predictions += inputs.size(0)\n",
    "\n",
    "    # return loss and evaluation metric\n",
    "    loss = running_loss / (step + 1.0)\n",
    "    accuracy = total_correct / total_predictions\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3521e78",
   "metadata": {},
   "source": [
    "## **Step 3: Train MobileNet-v2 on Beans**\n",
    "\n",
    "First, we will train a dense version of MobileNetv2 on the Beans dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d554578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download pre-trained model, setup classification head\n",
    "model = torchvision.models.mobilenet_v2(weights=torchvision.models.MobileNet_V2_Weights.DEFAULT)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, NUM_LABELS)\n",
    "model.to(device)\n",
    "\n",
    "# setup loss function and optimizer\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=8e-3) # lr will be override by sparseml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08337acc",
   "metadata": {},
   "source": [
    "Next, we will use SparseML's recipes to set the hyperparameters of training loop. In this case, we will use the following recipe:\n",
    "\n",
    "```yaml\n",
    "# Epoch and Learning-Rate variables\n",
    "num_epochs: 10.0\n",
    "init_lr: 0.0005\n",
    "\n",
    "training_modifiers:\n",
    "  - !EpochRangeModifier\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(num_epochs)\n",
    "\n",
    "  - !LearningRateFunctionModifier\n",
    "    final_lr: 0.0\n",
    "    init_lr: eval(init_lr)\n",
    "    lr_func: cosine\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(num_epochs)\n",
    "```\n",
    "\n",
    "As you can see, the recipe includes an `!EpochRangeModifier` and a `!LearningRateFunctionModifier`. These modifiers simply set the number of epochs to train for and the learning rate schedule. As a result, the final model will be dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceb62a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "# Epoch and Learning-Rate variables\r\n",
      "num_epochs: 10.0\r\n",
      "init_lr: 0.0005\r\n",
      "\r\n",
      "training_modifiers:\r\n",
      "  - !EpochRangeModifier\r\n",
      "    start_epoch: 0.0\r\n",
      "    end_epoch: eval(num_epochs)\r\n",
      "\r\n",
      "  - !LearningRateFunctionModifier\r\n",
      "    final_lr: 0.0\r\n",
      "    init_lr: eval(init_lr)\r\n",
      "    lr_func: cosine\r\n",
      "    start_epoch: 0.0\r\n",
      "    end_epoch: eval(num_epochs)"
     ]
    }
   ],
   "source": [
    "!cat ./recipes/mobilenetv2-beans-dense-recipe.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff717b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_recipe_path = \"./recipes/mobilenetv2-beans-dense-recipe.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee05d1",
   "metadata": {},
   "source": [
    "Next, we use SparseML's `ScheduledModifierManager` to parse and apply the recipe. The `manager.modify` function modifies and wraps the `model` and `optimizer` with the instructions from the recipe. You can use the `model` and `optimizer` just like standard PyTorch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1749e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ScheduledModifierManager and Optimizer wrapper\n",
    "manager = ScheduledModifierManager.from_yaml(dense_recipe_path)\n",
    "optimizer = manager.modify(model, optimizer, steps_per_epoch=len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ed163",
   "metadata": {},
   "source": [
    "Kick off the transfer learning loop. Our run reached ~99% validation accuracy after 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d00d175b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Training Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa6edfc1be94d68a8eee93e1691e3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1/10\n",
      "Training Loss: 0.47380749520027277\n",
      "Top 1 Acc: 0.8152804642166345\n",
      "\n",
      "Running Validation Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b703e41c6e804bbeacf25aace9f67748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 1/10\n",
      "Val Loss: 0.12894474416971208\n",
      "Top 1 Acc: 0.9774436090225563\n",
      "\n",
      "Running Training Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03a4c8f3706490ab3642e81b149c890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2/10\n",
      "Training Loss: 0.09328031384696563\n",
      "Top 1 Acc: 0.9690522243713733\n",
      "\n",
      "Running Validation Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a00338db9b54e1ebf5be2154d026bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 2/10\n",
      "Val Loss: 0.1064663665369153\n",
      "Top 1 Acc: 0.9548872180451128\n",
      "\n",
      "Running Training Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87566c12df134f38ad2d9f831998f01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3/10\n",
      "Training Loss: 0.04011029944839803\n",
      "Top 1 Acc: 0.9903288201160542\n",
      "\n",
      "Running Validation Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66ea6ca87944d63ab5d8a2a3fb07969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 3/10\n",
      "Val Loss: 0.06654092976823449\n",
      "Top 1 Acc: 0.9699248120300752\n",
      "\n",
      "Running Training Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0ab06fdf344eb4a98aa54b02f6e4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4/10\n",
      "Training Loss: 0.013448385923931544\n",
      "Top 1 Acc: 0.9990328820116054\n",
      "\n",
      "Running Validation Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d999410c2f42fe8ef5c695c51c908d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 4/10\n",
      "Val Loss: 0.04685080051422119\n",
      "Top 1 Acc: 0.9699248120300752\n",
      "\n",
      "Running Training Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178d61945ca94dffa214bdb40d7d6bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 5/10\n",
      "Training Loss: 0.011129878745343762\n",
      "Top 1 Acc: 0.9970986460348162\n",
      "\n",
      "Running Validation Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37456b087b96435dadb09b871e32694b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 5/10\n",
      "Val Loss: 0.04289984308416024\n",
      "Top 1 Acc: 0.9774436090225563\n",
      "\n",
      "Running Training Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8d82516d1d40659e6b2ae7aabf59fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 6/10\n",
      "Training Loss: 0.007474540554650241\n",
      "Top 1 Acc: 0.9990328820116054\n",
      "\n",
      "Running Validation Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bc30bbadd84ddebcc25510617ae2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 6/10\n",
      "Val Loss: 0.038813505135476586\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df44744907d4833b6e925f8ed7ef4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 7/10\n",
      "Training Loss: 0.022992545157621586\n",
      "Top 1 Acc: 0.9961315280464217\n",
      "\n",
      "Running Validation Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b42a80e927a41559038ed25a5ba85d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 7/10\n",
      "Val Loss: 0.038337701372802256\n",
      "Top 1 Acc: 0.9699248120300752\n",
      "\n",
      "Running Training Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb91384c3ee4dc0aa18605ca65295b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 8/10\n",
      "Training Loss: 0.01563219685693074\n",
      "Top 1 Acc: 0.9941972920696325\n",
      "\n",
      "Running Validation Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3a2318d0d14f12b79e6d011afecaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 8/10\n",
      "Val Loss: 0.052491285931319\n",
      "Top 1 Acc: 0.9774436090225563\n",
      "\n",
      "Running Training Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15077760bb514451a4fc7fbc45762a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 9/10\n",
      "Training Loss: 0.004495378677154694\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770b9912502a4f5eaf820fda80fb0b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 9/10\n",
      "Val Loss: 0.03483513812534511\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9f06d2c1b44fcb8273d49bd106a542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 10/10\n",
      "Training Loss: 0.003678643000911865\n",
      "Top 1 Acc: 1.0\n",
      "\n",
      "Running Validation Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a78c45e414444593c0dbcc0e08761e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 10/10\n",
      "Val Loss: 0.04160818513482809\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run transfer learning\n",
    "epoch = 0\n",
    "for epoch in range(manager.max_epochs):\n",
    "    # run training loop\n",
    "    epoch_name = f\"{epoch + 1}/{manager.max_epochs}\"\n",
    "    print(f\"Running Training Epoch {epoch_name}\")\n",
    "    train_loss, train_acc = run_model_one_epoch(model, train_loader, criterion, device, train=True, optimizer=optimizer)\n",
    "    print(f\"Training Epoch: {epoch_name}\\nTraining Loss: {train_loss}\\nTop 1 Acc: {train_acc}\\n\")\n",
    "\n",
    "    # run validation loop\n",
    "    print(f\"Running Validation Epoch {epoch_name}\")\n",
    "    val_loss, val_acc = run_model_one_epoch(model, val_loader, criterion, device)\n",
    "    print(f\"Validation Epoch: {epoch_name}\\nVal Loss: {val_loss}\\nTop 1 Acc: {val_acc}\\n\")\n",
    "\n",
    "manager.finalize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparseml.pytorch.utils import ModuleExporter\n",
    "\n",
    "save_dir = \"dense_model\"\n",
    "exporter = ModuleExporter(model, output_dir=save_dir)\n",
    "exporter.export_pytorch(name=\"mobilenet-v2-dense-beans.pth\")\n",
    "exporter.export_onnx(torch.randn(1, 3, 224, 224), name=\"dense-model.onnx\", convert_qat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ce478",
   "metadata": {},
   "source": [
    "## Step 4: Prune The Model\n",
    "\n",
    "With a model trained on Beans, we are now ready to apply the GMP algorithm to prune the model. The GMP algorithm is an interative pruning algorithm. At the end of each epoch, we identify the lowest magnitude weights (those closest to 0) and remove them from the network starting from an initial level of sparsity until a final level of sparsity. The remaining nonzero weights are then fine-tuned onto training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8447d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./dense_model/training/mobilenet-v2-dense-beans.pth\")\n",
    "model = torchvision.models.mobilenet_v2()\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, NUM_LABELS)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# setup loss function and optimizer, LR will be overriden by sparseml\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=8e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f45e1",
   "metadata": {},
   "source": [
    "Next, we need to create a SparseML recipe which includes the GMP algorithm. The `!GlobalMagnitudePruningModifier` modifier instructs SparseML to apply the GMP algorithm at a global level (pruning the lowest magnitude weights across all layers).\n",
    "\n",
    "Firstly, we need to decide identify which parameters of the model to apply the GMP algorithm to. We can use the `get_prunable_layers` function to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44578399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0\n",
      "features.1.conv.0.0\n",
      "features.1.conv.1\n",
      "features.2.conv.0.0\n",
      "features.2.conv.1.0\n",
      "features.2.conv.2\n",
      "features.3.conv.0.0\n",
      "features.3.conv.1.0\n",
      "features.3.conv.2\n",
      "features.4.conv.0.0\n",
      "features.4.conv.1.0\n",
      "features.4.conv.2\n",
      "features.5.conv.0.0\n",
      "features.5.conv.1.0\n",
      "features.5.conv.2\n",
      "features.6.conv.0.0\n",
      "features.6.conv.1.0\n",
      "features.6.conv.2\n",
      "features.7.conv.0.0\n",
      "features.7.conv.1.0\n",
      "features.7.conv.2\n",
      "features.8.conv.0.0\n",
      "features.8.conv.1.0\n",
      "features.8.conv.2\n",
      "features.9.conv.0.0\n",
      "features.9.conv.1.0\n",
      "features.9.conv.2\n",
      "features.10.conv.0.0\n",
      "features.10.conv.1.0\n",
      "features.10.conv.2\n",
      "features.11.conv.0.0\n",
      "features.11.conv.1.0\n",
      "features.11.conv.2\n",
      "features.12.conv.0.0\n",
      "features.12.conv.1.0\n",
      "features.12.conv.2\n",
      "features.13.conv.0.0\n",
      "features.13.conv.1.0\n",
      "features.13.conv.2\n",
      "features.14.conv.0.0\n",
      "features.14.conv.1.0\n",
      "features.14.conv.2\n",
      "features.15.conv.0.0\n",
      "features.15.conv.1.0\n",
      "features.15.conv.2\n",
      "features.16.conv.0.0\n",
      "features.16.conv.1.0\n",
      "features.16.conv.2\n",
      "features.17.conv.0.0\n",
      "features.17.conv.1.0\n",
      "features.17.conv.2\n",
      "features.18.0\n",
      "classifier.1\n"
     ]
    }
   ],
   "source": [
    "# print parameters\n",
    "for (name, layer) in get_prunable_layers(model):\n",
    "    print(f\"{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c95228",
   "metadata": {},
   "source": [
    "We will apply pruning to each of the convs and exclude the classifier layer (which is the final projection head). Fortunately, SparseML allows us to pass regexes to identify layers in the network, so we can use the following list to identify the relevant layers for pruning:\n",
    "    \n",
    "    - 'features.0.0.weight'\n",
    "    - 'features.18.0.weight'\n",
    "    - 're:features.*.conv.*.weight'\n",
    "    - 're:features.*.conv.*.*.weight'\n",
    "\n",
    "Here is what the recipe looks like:\n",
    "\n",
    "```yaml\n",
    "# Epoch and Learning-Rate variables\n",
    "num_epochs: 13.0\n",
    "pruning_epochs: 10.0\n",
    "init_lr: 0.0005\n",
    "inter_func: cubic\n",
    "mask_type: unstructured\n",
    "\n",
    "training_modifiers:\n",
    "  - !EpochRangeModifier\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(num_epochs)\n",
    "\n",
    "  - !LearningRateFunctionModifier\n",
    "    final_lr: 0.0\n",
    "    init_lr: eval(init_lr)\n",
    "    lr_func: cosine\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(num_epochs)\n",
    "\n",
    "# Pruning\n",
    "pruning_modifiers:\n",
    "  - !GlobalMagnitudePruningModifier\n",
    "    init_sparsity: 0.05\n",
    "    final_sparsity: 0.90\n",
    "    start_epoch: 0.0\n",
    "    end_epoch: eval(pruning_epochs)\n",
    "    update_frequency: 1.0\n",
    "    params: \n",
    "        - 'features.0.0.weight'\n",
    "        - 'features.18.0.weight'\n",
    "        - 're:features.*.conv.*.weight'\n",
    "        - 're:features.*.conv.*.*.weight'\n",
    "    leave_enabled: True\n",
    "    inter_func: eval(inter_func)\n",
    "    mask_type: eval(mask_type)\n",
    "```\n",
    "\n",
    "This recipe specifies that we will run the GMP algorithm for the first 10 epochs. We start at an init_sparsity level of 5% and gradually increase sparsity to a final_sparsity level of 90% following a cubic curve. The pruning is applied in an unstructured manner, meaning that any weight can be pruned.\n",
    "\n",
    "Over the final 3 epochs, we will fine-tune the 90% pruned model further. Since we set leave_enabled=True the sparsity level will be maintained as the fine-tuning occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./recipes/mobilenetv2-beans-pruning-recipe.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "238f3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_recipe_path = \"./recipes/mobilenetv2-beans-pruning-recipe.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68646bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ScheduledModifierManager and Optimizer wrapper\n",
    "manager = ScheduledModifierManager.from_yaml(pruning_recipe_path)\n",
    "logger = TensorBoardLogger(log_path=\"./tensorboard_outputs\")\n",
    "optimizer = manager.modify(model, optimizer, loggers=[logger], steps_per_epoch=len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71213f1b",
   "metadata": {},
   "source": [
    "Next, kick off the GMP training loop. \n",
    "\n",
    "As you can see, we use the wrapped `optimizer` and `model` in the same way as above. SparseML parsed the recipe and updated the `optimizer` with the logic of GMP algorithm from the recipe. This allows you to just the `optimizer` and `model` as usual, with all of the pruning-related logic specified by the declarative recipe interface.\n",
    "\n",
    "Our 90% pruned model reaches ~99% validation accuracy (vs ~99% for the dense model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "601c8c21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Training Epoch 1/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1532a057991c4f92ae19103ed357b47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1/13\n",
      "Training Loss: 0.030314430911940606\n",
      "Top 1 Acc: 0.9893617021276596\n",
      "\n",
      "Running Validation Epoch 1/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8229930b27d4f22a4b9071e2047f0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 1/13\n",
      "Val Loss: 0.10016061989590526\n",
      "Top 1 Acc: 0.9699248120300752\n",
      "\n",
      "Running Training Epoch 2/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b044a0e5d8414ea68ee41547c4a27210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2/13\n",
      "Training Loss: 0.03320332106721418\n",
      "Top 1 Acc: 0.9903288201160542\n",
      "\n",
      "Running Validation Epoch 2/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dd99cf59ab499db75f0cebe474a798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 2/13\n",
      "Val Loss: 0.05205255227629095\n",
      "Top 1 Acc: 0.9774436090225563\n",
      "\n",
      "Running Training Epoch 3/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9d00403a5c4a4a951d7c4c7a280da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3/13\n",
      "Training Loss: 0.02863485404558367\n",
      "Top 1 Acc: 0.9922630560928434\n",
      "\n",
      "Running Validation Epoch 3/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e239549148104b41a2c845856c105288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 3/13\n",
      "Val Loss: 0.04446154618635774\n",
      "Top 1 Acc: 0.9849624060150376\n",
      "\n",
      "Running Training Epoch 4/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0394c6e5c0d749daae91ac40c14d9577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4/13\n",
      "Training Loss: 0.028403193393552847\n",
      "Top 1 Acc: 0.9932301740812379\n",
      "\n",
      "Running Validation Epoch 4/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7210b33d08c14e4191c0d843ff49bf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 4/13\n",
      "Val Loss: 0.021256184950470925\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 5/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb5a222c0314969b10b4f8bf123c607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 5/13\n",
      "Training Loss: 0.10820412065720919\n",
      "Top 1 Acc: 0.9671179883945842\n",
      "\n",
      "Running Validation Epoch 5/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed07d03c2d4e4dfc8fb1d5b39d67a789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 5/13\n",
      "Val Loss: 0.07088811788707972\n",
      "Top 1 Acc: 0.9774436090225563\n",
      "\n",
      "Running Training Epoch 6/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94599ac85bd46b0ac5ca2200745ce42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 6/13\n",
      "Training Loss: 0.21380004890714632\n",
      "Top 1 Acc: 0.9216634429400387\n",
      "\n",
      "Running Validation Epoch 6/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a137efb0df4a78879678d686263c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 6/13\n",
      "Val Loss: 0.07981351003982126\n",
      "Top 1 Acc: 0.9774436090225563\n",
      "\n",
      "Running Training Epoch 7/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bf542d5d09438d93969342de4fab9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 7/13\n",
      "Training Loss: 0.19059311598539352\n",
      "Top 1 Acc: 0.9332688588007737\n",
      "\n",
      "Running Validation Epoch 7/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177ed7c1ade646f092ba59bafb462b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 7/13\n",
      "Val Loss: 0.07885787561535836\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 8/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e04f218de44f8ea10e4b261f9473d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 8/13\n",
      "Training Loss: 0.14277072397596907\n",
      "Top 1 Acc: 0.965183752417795\n",
      "\n",
      "Running Validation Epoch 8/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be70a6fffa6f419f82f87212155b98fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 8/13\n",
      "Val Loss: 0.08072680607438087\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 9/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246b3bf84568417f97c4bae88f83b4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 9/13\n",
      "Training Loss: 0.11926381854396878\n",
      "Top 1 Acc: 0.9680851063829787\n",
      "\n",
      "Running Validation Epoch 9/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41b1ccbde8c4857897e7b16758260dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 9/13\n",
      "Val Loss: 0.08937856331467628\n",
      "Top 1 Acc: 0.9849624060150376\n",
      "\n",
      "Running Training Epoch 10/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacdaf91b1e9436890b621b5095bfe05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 10/13\n",
      "Training Loss: 0.08645325391130014\n",
      "Top 1 Acc: 0.9854932301740812\n",
      "\n",
      "Running Validation Epoch 10/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d39663296c0495f9a9578847a5678f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 10/13\n",
      "Val Loss: 0.06663795448839664\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 11/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e738fd26e239454387c7b528b6b0e33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 11/13\n",
      "Training Loss: 0.07962510655775215\n",
      "Top 1 Acc: 0.9816247582205029\n",
      "\n",
      "Running Validation Epoch 11/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfbbe2836864d618f6dea028dd7c37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 11/13\n",
      "Val Loss: 0.0655035775154829\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 12/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba18ba8e68a46169c9faef52291598a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 12/13\n",
      "Training Loss: 0.08157054532432195\n",
      "Top 1 Acc: 0.9825918762088974\n",
      "\n",
      "Running Validation Epoch 12/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc213871f6bf4851817a59c8a282b98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 12/13\n",
      "Val Loss: 0.061416388303041455\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n",
      "Running Training Epoch 13/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac56ff40a6e348ae88f943de31efce6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 13/13\n",
      "Training Loss: 0.06805486869857166\n",
      "Top 1 Acc: 0.9874274661508704\n",
      "\n",
      "Running Validation Epoch 13/13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf25c82c70c449ebbdd8b6bf4493075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch: 13/13\n",
      "Val Loss: 0.06589164286851883\n",
      "Top 1 Acc: 0.9924812030075187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run GMP algorithm\n",
    "epoch = 0\n",
    "for epoch in range(manager.max_epochs):\n",
    "    # run training loop\n",
    "    epoch_name = f\"{epoch + 1}/{manager.max_epochs}\"\n",
    "    print(f\"Running Training Epoch {epoch_name}\")\n",
    "    train_loss, train_acc = run_model_one_epoch(model, train_loader, criterion, device, train=True, optimizer=optimizer)\n",
    "    print(f\"Training Epoch: {epoch_name}\\nTraining Loss: {train_loss}\\nTop 1 Acc: {train_acc}\\n\")\n",
    "\n",
    "    # run validation loop\n",
    "    print(f\"Running Validation Epoch {epoch_name}\")\n",
    "    val_loss, val_acc = run_model_one_epoch(model, val_loader, criterion, device)\n",
    "    print(f\"Validation Epoch: {epoch_name}\\nVal Loss: {val_loss}\\nTop 1 Acc: {val_acc}\\n\")\n",
    "    \n",
    "    logger.log_scalar(\"Metrics/Loss (Train)\", train_loss, epoch)\n",
    "    logger.log_scalar(\"Metrics/Accuracy (Train)\", train_acc, epoch)\n",
    "    logger.log_scalar(\"Metrics/Loss (Validation)\", val_loss, epoch)\n",
    "    logger.log_scalar(\"Metrics/Accuracy (Validation)\", val_acc, epoch)\n",
    "    \n",
    "manager.finalize(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b80c2",
   "metadata": {},
   "source": [
    "Here is a sample of the TensorBoard output, showing the validation accuracy, a particular layer's sparsity level, and the learning rate over time.\n",
    "\n",
    "![tensorboard output](./images/mobilenetv2-beans-tensorboard-output.png)\n",
    "\n",
    "We can print layer-by-layer sparsity as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cae6584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0.weight: 0.4861\n",
      "features.1.conv.0.0.weight: 0.4688\n",
      "features.1.conv.1.weight: 0.5156\n",
      "features.2.conv.0.0.weight: 0.5547\n",
      "features.2.conv.1.0.weight: 0.2905\n",
      "features.2.conv.2.weight: 0.4865\n",
      "features.3.conv.0.0.weight: 0.6102\n",
      "features.3.conv.1.0.weight: 0.4961\n",
      "features.3.conv.2.weight: 0.6111\n",
      "features.4.conv.0.0.weight: 0.5229\n",
      "features.4.conv.1.0.weight: 0.2731\n",
      "features.4.conv.2.weight: 0.5187\n",
      "features.5.conv.0.0.weight: 0.6901\n",
      "features.5.conv.1.0.weight: 0.5880\n",
      "features.5.conv.2.weight: 0.7126\n",
      "features.6.conv.0.0.weight: 0.6934\n",
      "features.6.conv.1.0.weight: 0.6111\n",
      "features.6.conv.2.weight: 0.7402\n",
      "features.7.conv.0.0.weight: 0.5495\n",
      "features.7.conv.1.0.weight: 0.3634\n",
      "features.7.conv.2.weight: 0.6127\n",
      "features.8.conv.0.0.weight: 0.8370\n",
      "features.8.conv.1.0.weight: 0.7405\n",
      "features.8.conv.2.weight: 0.8673\n",
      "features.9.conv.0.0.weight: 0.8272\n",
      "features.9.conv.1.0.weight: 0.7384\n",
      "features.9.conv.2.weight: 0.8634\n",
      "features.10.conv.0.0.weight: 0.8271\n",
      "features.10.conv.1.0.weight: 0.7870\n",
      "features.10.conv.2.weight: 0.8725\n",
      "features.11.conv.0.0.weight: 0.7251\n",
      "features.11.conv.1.0.weight: 0.7980\n",
      "features.11.conv.2.weight: 0.7725\n",
      "features.12.conv.0.0.weight: 0.8820\n",
      "features.12.conv.1.0.weight: 0.7932\n",
      "features.12.conv.2.weight: 0.9047\n",
      "features.13.conv.0.0.weight: 0.8708\n",
      "features.13.conv.1.0.weight: 0.8169\n",
      "features.13.conv.2.weight: 0.9118\n",
      "features.14.conv.0.0.weight: 0.7866\n",
      "features.14.conv.1.0.weight: 0.6883\n",
      "features.14.conv.2.weight: 0.8266\n",
      "features.15.conv.0.0.weight: 0.9452\n",
      "features.15.conv.1.0.weight: 0.7866\n",
      "features.15.conv.2.weight: 0.9565\n",
      "features.16.conv.0.0.weight: 0.9238\n",
      "features.16.conv.1.0.weight: 0.7926\n",
      "features.16.conv.2.weight: 0.9577\n",
      "features.17.conv.0.0.weight: 0.8770\n",
      "features.17.conv.1.0.weight: 0.9112\n",
      "features.17.conv.2.weight: 0.9516\n",
      "features.18.0.weight: 0.9784\n",
      "classifier.1.weight: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for (name, layer) in get_prunable_layers(model):\n",
    "    print(f\"{name}.weight: {tensor_sparsity(layer.weight).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00805b02",
   "metadata": {},
   "source": [
    "Finally, export your model to ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a44061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"experiment-0\"\n",
    "exporter = ModuleExporter(model, output_dir=save_dir)\n",
    "exporter.export_pytorch(name=\"mobilenet_v2-sparse-beans.pth\")\n",
    "exporter.export_onnx(torch.randn(1, 3, 224, 224), name=\"sparse-model.onnx\", convert_qat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960612c",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "The resulting model is is 90% sparse and achieves validation accuracy of ~99% (vs the unoptimized dense model at ~99%) without much hyperparameter search.\n",
    "\n",
    "Key hyperparameter experiments you may want to run include:\n",
    "- Learning rate\n",
    "- Learning rate schedule\n",
    "- Sparsity level\n",
    "- Number of pruning epochs\n",
    "\n",
    "DeepSparse supports speedup from pruning and quantization. To reach maximum performance, check out our examples of quantizing a model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
