{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sub>&copy; 2021 Neuralmagic, Inc. // [Neural Magic Legal](https://neuralmagic.com/legal)</sub> \n",
    "\n",
    "# Keras Classification Model Pruning using SparseML\n",
    "\n",
    "This notebook provides a step-by-step walkthrough for pruning an already trained (dense) model to enable better performance at inference time using the DeepSparse Inference Engine. You will:\n",
    "- Set up the model and dataset\n",
    "- Integrate the Keras training flow with SparseML\n",
    "- Prune the model using the Keras+SparseML flow\n",
    "- Export to [ONNX](https://onnx.ai/)\n",
    "\n",
    "Reading through this notebook will be reasonably quick to gain an intuition for how to plug SparseML into your Keras training flow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Requirements\n",
    "To run this notebook, you will need the following packages already installed:\n",
    "* SparseML and SparseZoo\n",
    "* Keras\n",
    "* TensorBoard\n",
    "\n",
    "You can install any package that is not already present via `pip`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Setting Up the Model and Dataset\n",
    "\n",
    "In this notebook, you will prune a simple Convolution Neural Network model trained on the MNIST dataset. The pretrained model's architecture and weights are downloaded from the SparseZoo model repo. The dataset is downloaded directly from  Keras datasets library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines a procedure to download a model from the SparseZoo; additionally, for convenience it also returns the path to an optimization recipe. You construct a Keras model instance from the pretrained to prune in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "from sparsezoo.models import Zoo\n",
    "\n",
    "# Root directory for the notebook artifacts\n",
    "root_dir = \"./notebooks/keras\"\n",
    "\n",
    "def download_model_and_recipe(root_dir: str):\n",
    "    \"\"\"\n",
    "    Download pretrained model and a pruning recipe\n",
    "    \"\"\"\n",
    "    model_dir = os.path.join(root_dir, \"mnist\")\n",
    "    zoo_model = Zoo.load_model(\n",
    "            domain=\"cv\",\n",
    "            sub_domain=\"classification\",\n",
    "            architecture=\"mnist\",\n",
    "            sub_architecture=None,\n",
    "            framework=\"keras\",\n",
    "            repo=\"sparseml\",\n",
    "            dataset=\"mnist\",\n",
    "            training_scheme=None,\n",
    "            optim_name=\"pruned\",\n",
    "            optim_category=\"conservative\",\n",
    "            optim_target=None,\n",
    "            override_parent_path=model_dir,\n",
    "        )\n",
    "    zoo_model.download()\n",
    "\n",
    "    model_file_path = zoo_model.framework_files[0].downloaded_path()\n",
    "    if not os.path.exists(model_file_path) or not model_file_path.endswith(\".h5\"):\n",
    "        raise RuntimeError(\"Model file not found: {}\".format(model_file_path))\n",
    "    recipe_file_path = zoo_model.recipes[0].downloaded_path()\n",
    "    if not os.path.exists(recipe_file_path):\n",
    "        raise RuntimeError(\"Recipe file not found: {}\".format(recipe_file_path))\n",
    "    return model_file_path, recipe_file_path\n",
    "\n",
    "model_file_path, recipe_file_path = download_model_and_recipe(root_dir)\n",
    "\n",
    "print(\"Loading model {}\".format(model_file_path))\n",
    "model = keras.models.load_model(model_file_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will download the MNIST dataset from Keras datasets library as follows. You will also normalize the data before using it for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "num_classes = 10\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before pruning the model, you could run the cell below to verify the accuracy of the model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss, accuracy: \", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Pruning the Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will prune the above pretrained Keras model using the SparseML model optimization library. Recall that a common training workflow in Keras is first to compile the model with the appropriate losses, metrics and an optimizer, then to train the model using the `fit()` method of the `Model` class. The SparseML library makes it easy to extend this training workflow to perform gradual pruning based on weight magnitudes.\n",
    "\n",
    "Given a pretrained model, the pruning workflow can be summarized as follows:\n",
    "1. Create a recipe for pruning, which could be done effectively using the Sparsify toolkit\n",
    "2. Instantiate a Keras optimizer instance (such as SGD or Adam)\n",
    "3. Instantiate a `ScheduledModifierManager` object from the recipe\n",
    "4. Enhance the model and optimizer with pruning data structures by calling the manager's `modify` method. At this step, you have options to define the loggers used during the pruning process. The results of this step are a model to be pruned, an optimizer that should be used and a list of callbacks\n",
    "5. [Optional] Add to the callback list any additional callbacks such as model checkpoint and the SparseML built-in LossesAndMetricsLogging callback\n",
    "6. Compile and fit the modified model using Keras built-in APIs, using the optimizer and callback list\n",
    "7. Erase the pruning information in the enhanced model, and get back the original model with pruned weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will set up a directory path for logging and the frequency for the logging update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Logging directory\n",
    "log_dir = \"/hdd/src/sparseml/notebooks/keras/tensorboard/mnist\"\n",
    "log_dir += \":\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(\"Logging directory: {}\".format(log_dir))\n",
    "\n",
    "# Number of steps before the next logging should take place\n",
    "# Use \"epoch\" or \"batch\" to log at every training epoch or batch (respectively)\n",
    "update_freq = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains steps described in the pruning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sparseml.keras.optim import ScheduledModifierManager\n",
    "from sparseml.keras.utils import TensorBoardLogger\n",
    "\n",
    "# Number of steps per epoch\n",
    "steps_per_epoch = math.ceil(len(x_train) / batch_size)\n",
    "\n",
    "# Create a manager from the recipe\n",
    "manager = ScheduledModifierManager.from_yaml(recipe_file_path)\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# Create a TensorBoardLogger instance\n",
    "loggers = TensorBoardLogger(log_dir=log_dir, update_freq=update_freq)\n",
    "\n",
    "# Modify the model and optimizer\n",
    "model_for_pruning, optimizer, callbacks = manager.modify(model, optimizer, steps_per_epoch, loggers=loggers)\n",
    "\n",
    "# Compile the modified model\n",
    "model_for_pruning.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "# Prune the model\n",
    "model_for_pruning.fit(x_train, y_train, batch_size=batch_size, epochs=manager.max_epochs,\n",
    "                      validation_data=(x_test, y_test), shuffle=True, callbacks=callbacks)\n",
    "\n",
    "print(\"Prunning finished\")\n",
    "\n",
    "# Verify the pruned model's accuracy\n",
    "res = model_for_pruning.evaluate(x_test, y_test)\n",
    "print(\"Validation loss, accuracy: \", res)\n",
    "\n",
    "# Erase the enhanced information used for pruning \n",
    "pruned_model = manager.finalize(model_for_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will observe the logging information in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Examine the Pruned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe the layers of the pruned Keras model using its `layers` property and `get_weights()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the layer index to examine the layers\n",
    "layer_index = 1\n",
    "pruned_model.layers[layer_index].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Exporting to ONNX\n",
    "\n",
    "Now that the model is fully recalibrated, you need to export it to an ONNX format, which is the format used by the DeepSparse. For Keras, exporting to ONNX is natively supported. In the cell block below, a convenience class, ModuleExporter(), is used to handle exporting.\n",
    "\n",
    "Once the model is saved as an ONNX ﬁle, it is ready to be used for inference with Neural Magic.  For saving a custom model, you can override the sample batch for ONNX graph freezing and locations to save to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparseml.keras.utils import ModelExporter\n",
    "\n",
    "save_dir = \"keras_classification\"\n",
    "\n",
    "exporter = ModelExporter(model, output_dir=save_dir)\n",
    "exporter.export_onnx(name=\"pruned_mnist.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations, you have pruned a model and exported it to ONNX for inference!  Next steps you can pursue include:\n",
    "* Pruning different models using SparseML\n",
    "* Trying different pruning and optimization recipes\n",
    "* Running your model on the DeepSparse Inference Engine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras_pruning)",
   "language": "python",
   "name": "keras_pruning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
